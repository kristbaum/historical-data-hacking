{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3963163a",
   "metadata": {},
   "source": [
    "# Datenanreicherung und Semantische Verknüpfung\n",
    "\n",
    "Einführung in Konzepte und Praktiken zur Anreicherung von Daten mit externem Wissen und deren semantischer Vernetzung, Thematisierung von Methoden zur präzisen Erfassung und Standardisierung historischer Zeitangaben (OpenRefine, Wikidata-Reconciliation, RDF Export, Unstruwwel / EDTF)\n",
    "\n",
    "# Task 2 – Datenanreicherung & Semantische Verknüpfung (Wikidata / GND)\n",
    "\n",
    "Ziel: Personen- und Objekt-Daten aus Task 1 (insb. `persons` und `building_person_roles`) mit externen Normdaten abgleichen (Wikidata, GND) und strukturierte Zusatzinformationen (Lebensdaten, alternative Namen, Berufe) übernehmen.\n",
    "\n",
    "> Voraussetzungen: Aufbereitete Long-Format-Tabellen aus Task 1 (oder OpenRefine Exporte). Optional: bereits bereinigte Personenlabels.\n",
    "\n",
    "## 0. Vorbereitung\n",
    "\n",
    "1. Exportiere aus Task 1 eine `persons.csv` mit Spalten: `person_id` (lokal/UUID oder leer), `person_label`.\n",
    "2. Erstelle in OpenRefine ein neues Projekt `persons_reconcile`.\n",
    "3. Entferne offensichtliche Klammerzusätze (z. B. Jahresangaben, wenn bereits vorhanden) mit GREL-RegEx – nur falls sie Matching behindern.\n",
    "\n",
    "Optional Python-Vorprofilierung (Distinct Labels, Häufigkeit) zur Priorisierung der wichtigsten Einträge.\n",
    "\n",
    "## 1. Wikidata Reconciliation (OpenRefine)\n",
    "\n",
    "1. Wähle Menü: Reconcile → Add Standard Service → URL: `https://wikidata.reconci.link/en/api` (oder passender Sprach-Endpunkt).\n",
    "2. Reconcile Spalte `person_label` gegen Wikidata (Type Suggestion \"human\" / Q5).\n",
    "3. Aktiviere \"Auto-match candidates with high confidence\".\n",
    "4. Identifiziere Einträge mit mehreren Kandidaten → manuell wählen.\n",
    "5. Markiere unsichere Fälle (Tag in einer neuen Spalte `wd_status`: `matched`, `ambiguous`, `none`).\n",
    "6. Füge neue Spalte `wikidata_id` hinzu: `cell.recon.match.id` (OpenRefine Funktion: \"Add column based on this column\" → Sprache GREL: `cell.recon.match.id`).\n",
    "7. Füge Spalte `wikidata_qlabel` hinzu: `cell.recon.match.name`.\n",
    "\n",
    "Qualitäts-Checks:\n",
    "\n",
    "- Prozentuale Match-Rate.\n",
    "- Anzahl Ambiguitäten.\n",
    "- Top 10 Labels ohne Treffer.\n",
    "\n",
    "## 2. Wikidata Enrichment (Lebensdaten)\n",
    "\n",
    "1. Wähle Reconcile-Spalte → \"Add columns from reconciled values\".\n",
    "2. Wähle Properties:\n",
    "   - P569 (Geburtsdatum)\n",
    "   - P570 (Sterbedatum)\n",
    "   - P19 (Geburtsort; Label)\n",
    "   - P20 (Sterbeort; Label)\n",
    "   - P106 (Beruf; Label)\n",
    "3. Spalten konsolidieren: ISO-Datum (YYYY-MM-DD) extrahieren → neue Felder `birth_year`, `death_year` (Regex: `^(\\\\d{4})`).\n",
    "4. Ableite `life_span`: `birth_year + '-' + death_year` (oder Platzhalter `?`).\n",
    "5. Prüfe auf inkonsistente Reihenfolge (Sterbejahr < Geburtsjahr) → Flag-Spalte.\n",
    "\n",
    "Python (optional) für Post-Processing:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "persons = pd.read_csv('persons_reconciled_wikidata.csv', dtype=str)\n",
    "for col in ['P569','P570']:\n",
    "   persons[col] = persons[col].str.extract(r'^(\\d{4})', expand=False)\n",
    "persons['life_span'] = persons[['P569','P570']].apply(lambda r: f\"{r.P569 or '?'}-{r.P570 or '?'}\", axis=1)\n",
    "```\n",
    "\n",
    "## 3. GND Reconciliation (Entity-Fishing / DNB SRU / VIAF)\n",
    "\n",
    "Ziel: Ergänzung GND-IDs (P227) für bereits gematchte Wikidata-Einträge oder direkte GND-Suche.\n",
    "\n",
    "Varianten:\n",
    "\n",
    "- a) Wikidata Already Contains GND: Hole P227 (GND-ID) über zusätzlichen Property-Import.\n",
    "- b) Direkter GND-Abgleich (OpenRefine Custom Service) – falls Service verfügbar.\n",
    "\n",
    "Schritt a (empfohlen, schnell):\n",
    "\n",
    "1. In OpenRefine erneut \"Add columns from reconciled values\" → wähle P227.\n",
    "2. Prüfe Format (Normform: Ziffern + 'X' möglich). Normalisiere: entferne Leerzeichen.\n",
    "\n",
    "Schritt b (optional / falls Zeit):\n",
    "\n",
    "1. Erstelle Liste verbleibender Personen ohne Wikidata Match.\n",
    "2. Baue Skript zur GND SRU Suche (Z39.50 / SRU API) – optional, nicht Teil Grundworkflow.\n",
    "\n",
    "## 4. Zusammenführung & Normalisierung\n",
    "\n",
    "1. Erstelle finalen Personen-DataFrame mit Feldern:\n",
    "   - `person_local_id`\n",
    "   - `person_label`\n",
    "   - `wikidata_id`\n",
    "   - `gnd_id`\n",
    "   - `birth_year`, `death_year`, `life_span`\n",
    "   - `birth_place_label`, `death_place_label`\n",
    "   - `occupations` (kommagetrennte Labels)\n",
    "2. Explodiere Mehrfachberufe (falls nötig) in separate Tabelle `person_occupations`.\n",
    "3. Vereinheitliche Orte (Mapping auf kontrollierte Gazetteer-IDs optional für Task 3).\n",
    "\n",
    "## 5. Ableitung Historischer Zeit-Features (EDTF / Unsicherheiten)\n",
    "\n",
    "1. Konvertiere `life_span` in EDTF:\n",
    "   - Nur Geburtsjahr bekannt: `YYYY/..`\n",
    "   - Nur Sterbejahr bekannt: `../YYYY`\n",
    "   - Beide vorhanden: `YYYY/YYYY`\n",
    "2. Spalte `life_span_edtf` hinzufügen.\n",
    "3. Optional: Unbestimmte Jahre (`ca.`) aus Labels erkennen → Intervall weiten (z. B. ±5 Jahre) und als `~` Qualifier in EDTF (Approximation) notieren: `1750~`.\n",
    "\n",
    "## 6. Daten-Qualitätsmetriken\n",
    "\n",
    "Erzeuge Report (Markdown / DataFrame):\n",
    "\n",
    "- Match-Rate Wikidata (% matched / total).\n",
    "- Anteil mit vollständigen Lebensdaten (Geburts- & Sterbejahr).\n",
    "- Anzahl distinct Berufe.\n",
    "- Häufigste 10 Berufe.\n",
    "- Anzahl Personen nur mit Geburts- oder nur mit Sterbejahr.\n",
    "- GND-Abdeckung (% mit P227).\n",
    "\n",
    "## 7. Aktualisierung Rollen-Tabelle\n",
    "\n",
    "1. Mergen `building_person_roles` mit angereicherter Personenliste auf `person_id` (oder Label fallback wenn ID fehlt – vorher disambiguieren!).\n",
    "2. Neue Felder ergänzen (`wikidata_id`, `life_span`, `occupations`).\n",
    "3. Export als `building_person_roles_enriched.parquet` / `.csv`.\n",
    "4. Optional: Filter Personen ohne Identifikatoren → Liste für spätere manuelle Recherche.\n",
    "\n",
    "## 8. SPARQL Validierung (Wikidata Query Service)\n",
    "\n",
    "Führe eine Beispiel-Abfrage aus (manuell im WDQS), um z. B. alle gefundenen `wikidata_id` zu verifizieren:\n",
    "\n",
    "```sparql\n",
    "SELECT ?person ?personLabel ?birth ?death WHERE {\n",
    "   VALUES ?person { wd:Q42 wd:Q5582 }  # Beispiel: Ersetze mit echten IDs\n",
    "   OPTIONAL { ?person wdt:P569 ?birth }\n",
    "   OPTIONAL { ?person wdt:P570 ?death }\n",
    "   SERVICE wikibase:label { bd:serviceParam wikibase:language \"de,en\". }\n",
    "}\n",
    "LIMIT 50\n",
    "```\n",
    "\n",
    "Dokumentiere Unterschiede zwischen SPARQL-Rückgaben und importierten OpenRefine-Attributen.\n",
    "\n",
    "## 9. Persistenz & Versionierung\n",
    "\n",
    "1. Lege Unterordner `enhanced/` an → speichere:\n",
    "   - `persons_enriched.parquet`\n",
    "   - `person_occupations.parquet`\n",
    "   - `building_person_roles_enriched.parquet`\n",
    "2. JSON Export der OpenRefine-Schritte: `openrefine_persons_history.json`.\n",
    "3. Kurzes `README_enriched.md` mit Feldbeschreibung.\n",
    "\n",
    "## 10. Reflexion / Offene Fragen\n",
    "\n",
    "- Welche Matching-Fälle blieben ungeklärt? (Beispiele aufführen)\n",
    "- Welche False Positives sind aufgetreten und wie erkennst du sie systematisch?\n",
    "- Welche Felder wären noch sinnvoll (z. B. VIAF, LOC)?\n",
    "- Wo entstehen potentielle Lizenz-/Nachnutzungsfragen?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
