{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ea027b",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1 – Daten-Preprocessing\n",
    "\n",
    "Ziel: Rohdaten aus `data/` (insb. `buildings.csv`) explorieren, bereinigen, normalisieren und für weitere Schritte (Anreicherung / Visualisierung) vorbereiten.\n",
    "\n",
    "## Pandas installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b67db3-48a4-4d99-a102-88506cc0abdd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kristbaum/Projects/historical-data-hacking/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/kristbaum/Projects/historical-data-hacking/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.4 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f24d377-a3fa-4682-ba8f-82fed59cec54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 715)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>appellation</th>\n",
       "      <th>alternativeNames</th>\n",
       "      <th>addressCountry</th>\n",
       "      <th>addressState</th>\n",
       "      <th>addressLocality</th>\n",
       "      <th>addressZip</th>\n",
       "      <th>addressStreet</th>\n",
       "      <th>locationLng</th>\n",
       "      <th>locationLat</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_1</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_2</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_3</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_4</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_5</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_6</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_7</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_8</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_9</th>\n",
       "      <th>TEMPLATE_PROVIDERS_OF_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48554093-289c-492a-a060-735d4e8971e8</td>\n",
       "      <td>Bad Buchau, Stiftskirche</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>Bad Buchau</td>\n",
       "      <td>88422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.611163</td>\n",
       "      <td>48.0674772</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843e2427-35b0-41ef-9299-0b44fb61e495</td>\n",
       "      <td>Bad Buchau, Abteigebäude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>Bad Buchau</td>\n",
       "      <td>88422</td>\n",
       "      <td>Schloßplatz 2</td>\n",
       "      <td>9.610800099999999</td>\n",
       "      <td>48.06731</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301e0950-c804-11e9-8a8f-6315b3a88f02</td>\n",
       "      <td>Leitheim, Schlossensemble, Weingärtnerhaus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>Leitheim</td>\n",
       "      <td>86687</td>\n",
       "      <td>Schloßstraße 5</td>\n",
       "      <td>10.883508912560208</td>\n",
       "      <td>48.7421674504304</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85c94cd0-c803-11e9-8a8f-6315b3a88f02</td>\n",
       "      <td>Leitheim, Kirche St. Blasius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>Leitheim</td>\n",
       "      <td>86687</td>\n",
       "      <td>Schloßstraße 3</td>\n",
       "      <td>10.883714569872827</td>\n",
       "      <td>48.74199234101888</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f67ae610-c802-11e9-8a8f-6315b3a88f02</td>\n",
       "      <td>Leitheim, Schloss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Bayern</td>\n",
       "      <td>Leitheim</td>\n",
       "      <td>86687</td>\n",
       "      <td>Schloßstraße 3</td>\n",
       "      <td>10.883350984238188</td>\n",
       "      <td>48.74199057228771</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 715 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  \\\n",
       "0  48554093-289c-492a-a060-735d4e8971e8   \n",
       "1  843e2427-35b0-41ef-9299-0b44fb61e495   \n",
       "2  301e0950-c804-11e9-8a8f-6315b3a88f02   \n",
       "3  85c94cd0-c803-11e9-8a8f-6315b3a88f02   \n",
       "4  f67ae610-c802-11e9-8a8f-6315b3a88f02   \n",
       "\n",
       "                                  appellation alternativeNames addressCountry  \\\n",
       "0                    Bad Buchau, Stiftskirche              NaN    Deutschland   \n",
       "1                    Bad Buchau, Abteigebäude              NaN    Deutschland   \n",
       "2  Leitheim, Schlossensemble, Weingärtnerhaus              NaN    Deutschland   \n",
       "3                Leitheim, Kirche St. Blasius              NaN    Deutschland   \n",
       "4                           Leitheim, Schloss              NaN    Deutschland   \n",
       "\n",
       "        addressState addressLocality addressZip   addressStreet  \\\n",
       "0  Baden-Württemberg      Bad Buchau      88422             NaN   \n",
       "1  Baden-Württemberg      Bad Buchau      88422   Schloßplatz 2   \n",
       "2             Bayern        Leitheim      86687  Schloßstraße 5   \n",
       "3             Bayern        Leitheim      86687  Schloßstraße 3   \n",
       "4             Bayern        Leitheim      86687  Schloßstraße 3   \n",
       "\n",
       "          locationLng        locationLat  ... TEMPLATE_PROVIDERS_OF_1  \\\n",
       "0            9.611163         48.0674772  ...                     NaN   \n",
       "1   9.610800099999999           48.06731  ...                     NaN   \n",
       "2  10.883508912560208   48.7421674504304  ...                     NaN   \n",
       "3  10.883714569872827  48.74199234101888  ...                     NaN   \n",
       "4  10.883350984238188  48.74199057228771  ...                     NaN   \n",
       "\n",
       "  TEMPLATE_PROVIDERS_OF_2 TEMPLATE_PROVIDERS_OF_3 TEMPLATE_PROVIDERS_OF_4  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     NaN                     NaN                     NaN   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     NaN                     NaN                     NaN   \n",
       "\n",
       "  TEMPLATE_PROVIDERS_OF_5 TEMPLATE_PROVIDERS_OF_6 TEMPLATE_PROVIDERS_OF_7  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     NaN                     NaN                     NaN   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     NaN                     NaN                     NaN   \n",
       "\n",
       "  TEMPLATE_PROVIDERS_OF_8 TEMPLATE_PROVIDERS_OF_9 TEMPLATE_PROVIDERS_OF_10  \n",
       "0                     NaN                     NaN                      NaN  \n",
       "1                     NaN                     NaN                      NaN  \n",
       "2                     NaN                     NaN                      NaN  \n",
       "3                     NaN                     NaN                      NaN  \n",
       "4                     NaN                     NaN                      NaN  \n",
       "\n",
       "[5 rows x 715 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "buildings = pd.read_csv('../buildings.csv', dtype=str)\n",
    "# Begründung: Viele Spalten enthalten gemischte / freie Werte \n",
    "# → zunächst Strings vermeiden fehlerhafte automatische Typkonvertierungen.\n",
    "print(buildings.shape)\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b0bb3-877b-440d-8196-445904f7f175",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Erste Profilierung\n",
    "\n",
    "1. Zähle Null/Leer-Werte pro Spalte (`''`, `' '`, `NaN`).\n",
    "2. Ermittle Anteil gefüllter Werte für Kernfelder: `ID`, `appellation`, `verbaleDating`, `locationLat`, `locationLng`.\n",
    "3. Erzeuge eine Kurztabelle (DataFrame) mit (Spaltenname, Non-Null %, Anzahl unterschiedlicher Werte, Beispielwerte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a54306dd-f123-442c-ba03-c683ed24883c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138692/1338647739.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  null_like = raw.replace({'': pd.NA, ' ': pd.NA})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>non_null_pct</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>MARBLE_WORKERS_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>MARBLE_WORKERS_10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>MARBLE_WORKERS_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>MARBLE_WORKERS_8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>MARBLE_WORKERS_7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>MARBLE_WORKERS_6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>MARBLE_WORKERS_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>MARBLE_WORKERS_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>MARBLE_WORKERS_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>MARBLE_WORKERS_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>MARBLE_WORKERS_OF_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>LEAD_RESOURCE_OF_10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>LEAD_RESOURCE_OF_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>LEAD_RESOURCE_OF_8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>MEMBERS_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column  non_null_pct  n_unique sample_values\n",
       "435     MARBLE_WORKERS_1           0.0         0              \n",
       "444    MARBLE_WORKERS_10           0.0         0              \n",
       "443     MARBLE_WORKERS_9           0.0         0              \n",
       "442     MARBLE_WORKERS_8           0.0         0              \n",
       "441     MARBLE_WORKERS_7           0.0         0              \n",
       "440     MARBLE_WORKERS_6           0.0         0              \n",
       "439     MARBLE_WORKERS_5           0.0         0              \n",
       "438     MARBLE_WORKERS_4           0.0         0              \n",
       "437     MARBLE_WORKERS_3           0.0         0              \n",
       "436     MARBLE_WORKERS_2           0.0         0              \n",
       "445  MARBLE_WORKERS_OF_1           0.0         0              \n",
       "434  LEAD_RESOURCE_OF_10           0.0         0              \n",
       "433   LEAD_RESOURCE_OF_9           0.0         0              \n",
       "432   LEAD_RESOURCE_OF_8           0.0         0              \n",
       "463            MEMBERS_9           0.0         0              "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = buildings.copy()\n",
    "null_like = raw.replace({'': pd.NA, ' ': pd.NA})\n",
    "profile = []\n",
    "for col in null_like.columns:\n",
    "    s = null_like[col]\n",
    "    profile.append({\n",
    "        'column': col,\n",
    "        'non_null_pct': s.notna().mean()*100,\n",
    "        'n_unique': s.nunique(dropna=True),\n",
    "        'sample_values': ', '.join(s.dropna().unique()[:3])\n",
    "    })\n",
    "profile_df = pd.DataFrame(profile).sort_values('non_null_pct')\n",
    "profile_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4defa",
   "metadata": {},
   "source": [
    "Fragen:\n",
    "\n",
    "- Welche Spalten sind fast leer und sollten ggf. ausgelagert / ignoriert werden?\n",
    "- Gibt es offensichtliche Duplikate bei `ID`?\n",
    "\n",
    "## 2. Bereinigung `verbaleDating`\n",
    "\n",
    "Spalte enthält verbale Zeitangaben / Bereiche wie: `\"1000-2020, 1773-1776\"`.\n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "1. Zerlege `verbaleDating` in einzelne Segmente (Trennzeichen: Komma) → normalisiere Leerzeichen.\n",
    "2. Identifiziere Bereiche (Pattern `YYYY-YYYY`) vs. Einzeljahre (`YYYY`).\n",
    "3. Baue eine normalisierte Tabelle `building_dates`: (`building_id`, `date_raw`, `year_start`, `year_end`, `is_range`, `precision`).\n",
    "4. Berechne je Gebäude: minimaler Start, maximaler Endwert → `chronology_min`, `chronology_max` und füge sie wieder dem Haupt-DataFrame hinzu.\n",
    "5. Detektiere Ausreißer (z. B. Jahr < 1000 oder > aktuelles Jahr). Markiere sie für manuelle Prüfung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1345e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "rows = []\n",
    "for _, r in buildings[['ID','verbaleDating']].fillna('').iterrows():\n",
    "    parts = [p.strip() for p in r.verbaleDating.split(',') if p.strip()]\n",
    "    for p in parts:\n",
    "        m_range = re.fullmatch(r'(\\d{4})-(\\d{4})', p)\n",
    "        m_year  = re.fullmatch(r'(\\d{4})', p)\n",
    "        if m_range:\n",
    "            y1, y2 = map(int, m_range.groups())\n",
    "            rows.append((r.ID, p, y1, y2, True, 'year-range'))\n",
    "        elif m_year:\n",
    "            y = int(m_year.group(1))\n",
    "            rows.append((r.ID, p, y, y, False, 'year'))\n",
    "        else:\n",
    "            # Nicht-parsbare Fälle separat behalten\n",
    "            rows.append((r.ID, p, None, None, None, 'unparsed'))\n",
    "\n",
    "building_dates = pd.DataFrame(rows, columns=['building_id','date_raw','year_start','year_end','is_range','precision'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac69222",
   "metadata": {},
   "source": [
    "Optionale Normalisierung unparsed Tokens: RegEx erweitern (z. B. `ca. 1750`, `17. Jh.` → Mapping Tabellen). Dokumentiere Annahmen!\n",
    "\n",
    "Metriken:\n",
    "\n",
    "- Anteil parsebarer Segmente.\n",
    "- Häufigste unparsed Muster (Top 10).\n",
    "\n",
    "## 3. Geodaten-Validierung+Auswertung\n",
    "\n",
    "1. Konvertiere `locationLat` / `locationLng` zu Float; markiere Zeilen, bei denen das misslingt.\n",
    "2. Prüfe Wertebereiche (Lat ∈ [-90, 90], Lng ∈ [-180, 180]). Auf Hessen beschränken mit Geokoordinaten und Geoshape.....\n",
    "3. Erstelle Spalten `coord_valid` (bool) und `coord_quality` (Enum: `valid`, `out_of_range`, `non_numeric`).\n",
    "4. Optional: Entferne identische Koordinaten-Duplikate, falls mehrere Gebäude dieselben Koordinaten teilen sollen – dokumentiere Entscheidungslogik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05462199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138692/19503827.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  coords = buildings[['locationLat','locationLng']].applymap(to_float)\n"
     ]
    }
   ],
   "source": [
    "def to_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except (TypeError, ValueError):\n",
    "        return pd.NA\n",
    "coords = buildings[['locationLat','locationLng']].applymap(to_float)\n",
    "valid_lat = coords.locationLat.between(-90,90)\n",
    "valid_lng = coords.locationLng.between(-180,180)\n",
    "buildings['coord_valid'] = valid_lat & valid_lng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3269c",
   "metadata": {},
   "source": [
    "## 4. Normalisierung mehrfacher Rollen-/Personenfelder\n",
    "\n",
    "Viele Spalten enden auf Sequenzen `_1`…`_10` (z. B. `ARCHITECTS_1`, `ARCHITECTS_2`, ...). Werteform: `uuid|Nachname, Vorname`.\n",
    "\n",
    "Ziel: Long-Format-Relation `building_person_roles`:\n",
    "(`building_id`, `role` (z. B. `ARCHITECTS`), `sequence` (Nummer), `person_id` (UUID), `person_label`).\n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "1. Identifiziere alle Basis-Rollen (Teil vor letztem `_` + Ziffern).\n",
    "2. Iteriere über alle diese Spalten, extrahiere Werte ≠ leer.\n",
    "3. Teile an erster Pipe `|` → `person_id`, zweiter Teil `person_label` (Fallback: kompletter String falls kein `|`).\n",
    "4. Entferne potenzielle Dubletten (gleiche Kombination building_id + role + person_id).\n",
    "5. Erzeuge optionale Personentabelle `persons` (distinct `person_id`, `person_label`, `label_clean`).\n",
    "6. Bereinige `person_label`: Whitespace trimmen, vereinheitliche Kommaspacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce84ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_cols = [c for c in buildings.columns if re.search(r'_\\d+$', c)]\n",
    "base_roles = sorted(set(re.sub(r'_\\d+$','', c) for c in role_cols))\n",
    "rows = []\n",
    "for role in base_roles:\n",
    "    for i in range(1, 11):\n",
    "        col = f'{role}_{i}'\n",
    "        if col not in buildings.columns: \n",
    "            continue\n",
    "        for _, r in buildings[['ID', col]].iterrows():\n",
    "            val = r[col]\n",
    "            if pd.isna(val) or not str(val).strip():\n",
    "                continue\n",
    "            if '|' in val:\n",
    "                pid, label = val.split('|',1)\n",
    "            else:\n",
    "                pid, label = None, val\n",
    "            rows.append((r.ID, role, i, pid, label.strip()))\n",
    "\n",
    "building_person_roles = pd.DataFrame(rows, columns=['building_id','role','sequence','person_id','person_label'])\n",
    "persons = (building_person_roles\n",
    "           .dropna(subset=['person_label'])\n",
    "           .groupby(['person_id','person_label'], dropna=False)\n",
    "           .size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac288ef",
   "metadata": {},
   "source": [
    "Validierung:\n",
    "\n",
    "- Wie viele Rollen wurden extrahiert?\n",
    "- Top 3 Personen je Rolle.\n",
    "\n",
    "## 5. Konsolidierung & Export\n",
    "\n",
    "1. Schlanken Haupt-DataFrame erstellen (`buildings_core`): wesentliche Attribute (ID, appellation, address*, chronology_min/max, coord_valid, locationLat/Lng als Float).\n",
    "2. Daten in Unterordner `processed/` exportieren:\n",
    "   - `buildings_core.parquet`\n",
    "   - `building_dates.parquet`\n",
    "   - `building_person_roles.parquet`\n",
    "   - `persons.parquet`\n",
    "3. Zusätzlich CSV-Export für Interoperabilität (UTF-8, `index=False`).\n",
    "4. README-Ergänzung (Kurzbeschreibung der erzeugten Dateien) – (Kann in Task 4 weiter genutzt werden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e324e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out = Path(\u001b[33m'\u001b[39m\u001b[33m../processed\u001b[39m\u001b[33m'\u001b[39m); out.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m buildings_core.to_parquet(out / \u001b[33m'\u001b[39m\u001b[33mbuildings_core.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m building_dates.to_parquet(out / \u001b[33m'\u001b[39m\u001b[33mbuilding_dates.parquet\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "out = Path('../processed'); out.mkdir(exist_ok=True)\n",
    "buildings_core.to_parquet(out / 'buildings_core.parquet')\n",
    "building_dates.to_parquet(out / 'building_dates.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814fd55",
   "metadata": {},
   "source": [
    "## 6. Qualitätsmetriken & Checks\n",
    "\n",
    "Erzeuge kleine Metriken (als DataFrame oder Markdown):\n",
    "\n",
    "- Parsebarkeit Datum (%).\n",
    "- Anzahl unparsed Datumseinträge.\n",
    "- Anzahl extrahierter Personenbeziehungen.\n",
    "- #Distinct Personen.\n",
    "- Anteil gültiger Koordinaten.\n",
    "\n",
    "## OpenRefine\n",
    "\n",
    "Ziel: Schnelle, reproduzierbare Bereinigung & Normalisierung zentraler Felder aus `buildings.csv` mittels OpenRefine.\n",
    "\n",
    "> Fokus: Sicht auf typische OpenRefine-Operationen (Facets, Clustering, Transformations, Splits, Rekonsilierungsvorbereitung). Dauer: ca. 30–40 Minuten.\n",
    "\n",
    "### 1. Import\n",
    "\n",
    "- Lade `buildings.csv` in OpenRefine.\n",
    "- Alle Spalten zunächst als Text lassen (kein Auto-Parsing von Zahlen/Datumsangaben aktivieren).\n",
    "- Projektname: `buildings_raw`.\n",
    "\n",
    "### 2. Grundlegende Sichtbarkeit\n",
    "\n",
    "- Entferne (nur in der Ansicht, nicht dauerhaft) extrem leere Spalten via Facet → „Facet by blank“ und spätere Auswahl für Export.\n",
    "- Erzeuge eine Text-Facet auf `appellation` → erkenne Varianten / Dubletten.\n",
    "\n",
    "### 3. Bereinigung `verbaleDating`\n",
    "\n",
    "Ziel: Segmentierung & Vor-Normalisierung für spätere Python-Verarbeitung.\n",
    "\n",
    "Schritte:\n",
    "\n",
    "1. Expression (GREL) Trim: `value.trim()` (Spalte bearbeiten → Zellen transformieren).\n",
    "2. Ersetze mehrere Leerzeichen: `value.replace(/\\s+/,' ')`.\n",
    "3. Split bei Komma (Spaltenmenü → „Edit cells → Split multi-valued cells“ → Separator `,`).\n",
    "4. Neue Spalte aus dieser (JSON-Serialisierung einzelner Werte für Kontrolle): `value` (Beibehalten). Optional: Werte mit Regex-Facet `^[0-9]{3,4}(-[0-9]{3,4})?$` filtern (parsbar vs. unparsed).\n",
    "5. Erzeuge Booleanspalte `is_range`: GREL: `value.match(/^[0-9]{3,4}-[0-9]{3,4}$/) != null`.\n",
    "6. Erzeuge Spalten `year_start` und `year_end`:\n",
    "   - Falls Range: `value.match(/^(\\d{3,4})-(\\d{3,4})$/)[0]` & `[1]`\n",
    "   - Falls Einzeljahr: `value` in beide kopieren.\n",
    "7. Filtere Ausreißer: Facet `year_start` → Numeric Facet → Werte außerhalb 800–(aktuelles Jahr) markieren.\n",
    "\n",
    "Hinweis: Exportiere Zwischenergebnis als `building_dates_openrefine.csv` für Abgleich mit Pandas-Parsing.\n",
    "\n",
    "### 4. Personen-/Rollenfelder (Beispiel: ARCHITECTS)\n",
    "\n",
    "Ziel: Long-Format Grundlage.\n",
    "\n",
    "Schritte:\n",
    "\n",
    "1. Wähle Spalten `ARCHITECTS_1` … `ARCHITECTS_10`.\n",
    "2. „Edit columns → Join columns“ (Separator `||`), erzeuge Sammelspalte `ARCHITECTS_JOIN`.\n",
    "3. Split multi-valued cells an `||` → leere entfernen.\n",
    "4. Entferne Duplikate (Facet by text, Auswahl blank → ausschließen).\n",
    "5. Extrahiere UUID & Label:\n",
    "   - Neue Spalte `person_id`: GREL: `if(value.contains('|'), value.split('|')[0], null)`\n",
    "   - Neue Spalte `person_label_raw`: GREL: `if(value.contains('|'), value.split('|')[1], value)`\n",
    "6. Clean Label: Neue Spalte `person_label`: `person_label_raw.trim().replace(/\\s*,\\s*/, ', ')`.\n",
    "7. Cluster (Edit cells → Cluster & edit) auf `person_label` (Method: key collision + metaphone3). Prüfe Zusammenführungen.\n",
    "8. Export als `architects_roles.csv` (Spalten: `building_row_index` / `person_id` / `person_label`). Optional: füge Quellspalte `ARCHITECTS` hinzu.\n",
    "\n",
    "### 5. Vorbereitung für Wikidata-Reconciliation\n",
    "\n",
    "Ziel: Spalte (z. B. `appellation` oder aufbereitete Personennamen) für spätere Abgleichung.\n",
    "\n",
    "Schritte:\n",
    "\n",
    "1. Entferne offensichtliche Zusätze (Regex Replace): Beispiel: `value.replace(/,\\s*Deutschland$/,'')` (nur wenn sinnvoll!).\n",
    "2. Normalisiere Großschreibung: `value.toTitlecase()` (sparsam einsetzen, um historische Schreibweisen nicht zu verfälschen).\n",
    "3. Exportiere Liste eindeutiger Werte (`Facet → Export → tabular`) als `appellations_unique.csv`.\n",
    "\n",
    "### 6. Audit & Undo/Redo\n",
    "\n",
    "- Nutze das Undo/Redo Panel, dokumentiere die angewandten Schritte (Screenshot / JSON). Export: „Extract…“ → Speichere Transformations-JSON als `openrefine-history.json` für Reproduzierbarkeit.\n",
    "\n",
    "### 7. Kurzer Qualitätsbericht (Markdown außerhalb OpenRefine)\n",
    "\n",
    "- Anzahl ursprünglicher vs. bereinigter `verbaleDating` Tokens.\n",
    "- Anzahl zusammengeführter Personenlabels durch Clustering.\n",
    "- Wichtige offene Problemfälle (Stichpunkte).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
